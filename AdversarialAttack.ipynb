{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d37e825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "302a49e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_old(image_raw):\n",
    "    image = tf.image.decode_image(image_raw)\n",
    "\n",
    "    # Pr√©traitement de l'image : on utilise directement la fonction de ResNet50\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    image = image[None, ...]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b21b45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_raw):\n",
    "    image_raw = cv2.cvtColor(image_raw, cv2.COLOR_BGR2RGB)\n",
    "    image_raw = cv2.resize(image_raw, (224, 224))\n",
    "    image_raw = np.expand_dims(image_raw, axis=0)\n",
    "    \n",
    "    return image_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d064defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_targeted_adversaries(model, baseImage, delta, classIdx, target, steps=500):\n",
    "    loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "    LR = 5e-3\n",
    "    EPS = 1.0 / 255\n",
    "    \n",
    "    previous_image_class = \"\"\n",
    "    previous_class_confidence = 0\n",
    "    \n",
    "    # Initialize optimizer and loss function\n",
    "    optimizer = Adam(learning_rate=LR)\n",
    "    sccLoss = SparseCategoricalCrossentropy()\n",
    "\n",
    "    # iterate over the number of steps\n",
    "    for step in range(0, steps):\n",
    "        # record our gradients\n",
    "        with tf.GradientTape() as tape:\n",
    "            # explicitly indicate that our perturbation vector should\n",
    "            # be tracked for gradient updates\n",
    "            tape.watch(delta)\n",
    "            # add our perturbation vector to the base image and\n",
    "            # preprocess the resulting image\n",
    "            image = tf.cast(baseImage + delta, tf.float32)\n",
    "            adversary = preprocess_input(image)\n",
    "            \n",
    "            # run this newly constructed image tensor through our\n",
    "            # model and calculate the loss with respect to the\n",
    "            # both the *original* class label and the *target*\n",
    "            # class label\n",
    "            predictions = model(adversary, training=False)\n",
    "            \n",
    "            #image_probs = model.predict(adversary)\n",
    "            _, image_class, class_confidence = tf.keras.applications.resnet50.decode_predictions(np.array(predictions), top=1)[0][0]\n",
    "            \n",
    "            if(previous_image_class != image_class or previous_class_confidence != int(class_confidence)):\n",
    "                print(image_class + \" \" + str(class_confidence*100) + \"%\")\n",
    "                \n",
    "            previous_image_class = image_class\n",
    "            previous_class_confidence = int(class_confidence)\n",
    "            \n",
    "            targetLoss = sccLoss(tf.convert_to_tensor([target]), predictions)\n",
    "            totalLoss = targetLoss#originalLoss + targetLoss\n",
    "            # check to see if we are logging the loss value, and if\n",
    "            # so, display it to our terminal\n",
    "            if step % 20 == 0:\n",
    "                print(\"step: {}, totalLoss: {} , targetLoss: {}\".format(step, totalLoss.numpy(), targetLoss.numpy()))\n",
    "        # calculate the gradients of loss with respect to the\n",
    "        # perturbation vector\n",
    "        gradients = tape.gradient(totalLoss, delta)\n",
    "        # update the weights, clip the perturbation vector, and\n",
    "        # update its value\n",
    "        optimizer.apply_gradients([(gradients, delta)])\n",
    "        delta.assign_add(tf.clip_by_value(delta, clip_value_min=-EPS, clip_value_max=EPS))\n",
    "        \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a72e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a, b):\n",
    "    return np.linalg.norm(np.array(a) - np.array(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40ebcf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image):\n",
    "    restored = image.numpy().squeeze()\n",
    "    restored = np.clip(restored, 0, 255).astype(\"uint8\")\n",
    "    restored = cv2.cvtColor(restored, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(\"adversarial.jpg\", restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b665601",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.resnet50.ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a916f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "image_raw = cv2.imread(\"chat.jpg\")\n",
    "image = preprocess_image(image_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a103e822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "golden_retriever 24.593152105808258%\n",
      "step: 0, totalLoss: 11.45362663269043 , targetLoss: 11.45362663269043\n",
      "Persian_cat 20.5671489238739%\n",
      "step: 20, totalLoss: 8.634535789489746 , targetLoss: 8.634535789489746\n",
      "step: 40, totalLoss: 6.5191545486450195 , targetLoss: 6.5191545486450195\n",
      "bittern 7.576622813940048%\n",
      "step: 60, totalLoss: 4.391037464141846 , targetLoss: 4.391037464141846\n",
      "coffeepot 6.370828300714493%\n",
      "teapot 11.032266169786453%\n",
      "step: 80, totalLoss: 2.106106758117676 , targetLoss: 2.106106758117676\n",
      "step: 100, totalLoss: 0.6692129373550415 , targetLoss: 0.6692129373550415\n",
      "step: 120, totalLoss: 0.22752180695533752 , targetLoss: 0.22752180695533752\n",
      "step: 140, totalLoss: 0.12037176638841629 , targetLoss: 0.12037176638841629\n",
      "step: 160, totalLoss: 0.08258318156003952 , targetLoss: 0.08258318156003952\n",
      "step: 180, totalLoss: 0.063374824821949 , targetLoss: 0.063374824821949\n",
      "step: 200, totalLoss: 0.051507800817489624 , targetLoss: 0.051507800817489624\n",
      "step: 220, totalLoss: 0.04492322355508804 , targetLoss: 0.04492322355508804\n",
      "step: 240, totalLoss: 0.03982502222061157 , targetLoss: 0.03982502222061157\n",
      "step: 260, totalLoss: 0.03668219596147537 , targetLoss: 0.03668219596147537\n",
      "step: 280, totalLoss: 0.03373406082391739 , targetLoss: 0.03373406082391739\n",
      "step: 300, totalLoss: 0.030797552317380905 , targetLoss: 0.030797552317380905\n",
      "step: 320, totalLoss: 0.028851253911852837 , targetLoss: 0.028851253911852837\n",
      "step: 340, totalLoss: 0.027589883655309677 , targetLoss: 0.027589883655309677\n",
      "step: 360, totalLoss: 0.02651337906718254 , targetLoss: 0.02651337906718254\n",
      "step: 380, totalLoss: 0.025626754388213158 , targetLoss: 0.025626754388213158\n",
      "step: 400, totalLoss: 0.024874817579984665 , targetLoss: 0.024874817579984665\n",
      "step: 420, totalLoss: 0.024070996791124344 , targetLoss: 0.024070996791124344\n",
      "step: 440, totalLoss: 0.02329937182366848 , targetLoss: 0.02329937182366848\n",
      "step: 460, totalLoss: 0.022967742756009102 , targetLoss: 0.022967742756009102\n",
      "step: 480, totalLoss: 0.022883741185069084 , targetLoss: 0.022883741185069084\n"
     ]
    }
   ],
   "source": [
    "baseImage = tf.constant(image, dtype=tf.float32)\n",
    "delta = tf.Variable(tf.zeros_like(baseImage), trainable=True)\n",
    "\n",
    "# Generate perturbation vector\n",
    "deltaUpdated = generate_targeted_adversaries(model, baseImage, delta, 794, 849)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d68ef887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply perturbation and save the image\n",
    "adverImage = (image + deltaUpdated)\n",
    "save_image(adverImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ccbe6585",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_probs = model.predict(adverImage)\n",
    "_, image_class, class_confidence = tf.keras.applications.resnet50.decode_predictions(image_probs, top=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "02989346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: saltshaker with 63.78558278083801% confidence\n"
     ]
    }
   ],
   "source": [
    "print(\"Found: \"+ image_class + \" with \" + str(class_confidence*100) + \"% confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b650696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
